# Manipulación de estructuras
library(tidyverse)
library(Rlab)
# Para realizar plots
library(ggplot2)
library(plotly)
# Manipulación de varios plots en una imagen.
library(gridExtra)
library(grid)
# Definición de variables o estructuras necesarias para el muestreo.
prob <- 0.5
m <- c(10, 50, 100, 1000)
n_individuos = 5000
main_bernoulli <- c()
means <- c()
# Generamos una población que se comporta como Bernoulli(p=0.5)
bernoulli = rbern(n_individuos, p = prob)
real_mean = mean(bernoulli)
# Por cada tamaño de muestras
for(i in m) {
# Saco una muestra de tamaño i de la población
sampling <- sample(bernoulli, i, replace = FALSE)
# Las concateno al vector principal y calculo el estimador
main_bernoulli <- append(main_bernoulli, sampling)
hat_p = mean(sampling)
means <- append(means, hat_p)
}
# Primero creamos un dataframe de los datos aleatorios, con atributo 'vals'
bern_dt <- data.frame(value=main_bernoulli[1:10])
# Posteriormente creamos el plot que mostraremos en pantalla
p1 <- ggplot(bern_dt, aes(x=value)) + # Elegimos el dataframe a plotear +
geom_histogram(aes(y=..count..), colour="black", fill="white") + # Creamos el Histograma
geom_vline(aes(xintercept=means[1]),
color="blue", linetype="solid", size=1) + # Ploteamos el estimador
geom_vline(aes(xintercept=real_mean),
color="red", linetype="solid", size=1) +  # Ploteamos la media real
ggtitle("sample size = 10") +
theme(plot.title = element_text(hjust = 0.5)) # Creamos el título y su tema
bern_dt <- data.frame(value=main_bernoulli[11:60])
p2 <- ggplot(bern_dt, aes(x=value)) +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
geom_vline(aes(xintercept=means[2]),
color="blue", linetype="solid", size=1) +
geom_vline(aes(xintercept=real_mean),
color="red", linetype="solid", size=1) +
ggtitle("sample size = 50") +
theme(plot.title = element_text(hjust = 0.5))
bern_dt <- data.frame(value=main_bernoulli[61:160])
p3 <- ggplot(bern_dt, aes(x=value)) +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
geom_vline(aes(xintercept=means[3]),
color="blue", linetype="solid", size=1) +
geom_vline(aes(xintercept=real_mean),
color="red", linetype="solid", size=1) +
ggtitle("sample size = 100") +
theme(plot.title = element_text(hjust = 0.5))
bern_dt <- data.frame(value=main_bernoulli[161:1160])
p4 <- ggplot(bern_dt, aes(x=value)) +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
geom_vline(aes(xintercept=means[4]),
color="blue", linetype="solid", size=1) +
geom_vline(aes(xintercept=real_mean),
color="red", linetype="solid", size=1) +
ggtitle("sample size = 1000") +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(p1, p2, p3, p4, ncol=2, nrow=2,
top = textGrob("Bernoulli Distribution \n n = 5000",
gp=gpar(fontsize=15)))
# Definimos tamaños de muestreo
tamano_muestra = 30
n_muestras = 5000
# Generamos una exponencial para luego generar el subsampling de ella
exponencial = rexp(10000, rate = 2)
# Obtenemos la media poblacional de la exponencial
exp.mean <- mean(exponencial)
# Creamos el data.frame general para poder graficarlo posteriormente:
confidence <- data.frame(
mean = double(),
error = double(),
group = integer()
)
# Sampling distribution, calculo del intervalo de confianza y proporción.
for (i in 1:n_muestras){
# En base a la distribución exponencial, generamos multiples sampling distribution.
sampling <- sample(exponencial, tamano_muestra, replace = FALSE)
# Se estima la media del muestreos y el error estándar
sample.mean <- mean(sampling)
sample.sd <- sd(sampling)
sample.se <- sample.sd/sqrt(tamano_muestra)
# Calculamos el t_score y el margen de error para calcular el intervalo
alpha = 0.05
t.score = qt(p=alpha/2, df = tamano_muestra - 1, lower.tail=F)
margin.error <- t.score * sample.se
# Se determina si la media real pertenece al intervalo o no
g = "IN"
if (exp.mean >= sample.mean - margin.error && exp.mean <= sample.mean + margin.error){
# Si la media pertenece al intervalo calculado, es del grupo 0
g = "IN"
} else {
# Si la media no pertenece al intervalo, es del grupo 1
g = "OUT"
}
# Concatenamos al dataframe de la muestra los datos rescatados en cada
# iteración. Este dataframe contendrá toda la información para plotear.
z <- data.frame(mean = sample.mean, error = margin.error, group = factor(g))
confidence <- rbind(confidence, z)
}
# Plot de Intervalos de confianza (ver respuesta esperada)
# Utilizamos el dataframe creado con cada iteración
plot1 <- ggplot(confidence, aes(mean, c(1:5000), colour = group)) +
geom_point() +  # Creamos un gráfico de puntos
xlim(0, 1.5) +  # Añadimos límites para una visualización comoda
scale_color_manual(values=c("#83D7FE", "#FE83BB")) +  # Colores de cada punto
# Graficamos con geom_errorbar horizontal el intervalo de confianza por cada
# iteración. Este se calcula como la media calculada más-menos el error calculado.
geom_errorbarh(aes(xmax = mean + error, xmin = mean - error)) +
# Añadimos una recta vertical que indique la media real.
geom_vline(aes(xintercept=exp.mean),
color="black", linetype="dotted", size=0.5) +
# Finalmente añadimos labels y un título.
labs(x="Means", y="Iteration") +
ggtitle("Intervalos de Confianza \n n = 5000, t = 30") +
theme(plot.title = element_text(hjust = 0.5))
plot1
# Plot de proporción de Intervalos de confianza
# Utilizando el mismo dataframe, crearemos un histograma simple con la cantidad
# de ocurrecinas de IN y OUT. En este caso el eje x es el grupo
plot2 <- ggplot(confidence, aes(x = group)) +
# Ponemos los límites verticales como la cantidad de iteraciones.
ylim(0, 5000) +
# Creamos el histograma con stat count para contar el grupo
geom_histogram(stat="count", color="black", fill="white") +
# Añadimos un texto en la parte superior de cada barra como el valor contado
# (parámetro ..count..) y lo operamos para que indique el porcentaje real
# del grupo sobre la muestra total
geom_text(stat= "count", aes(label=(..count.. /n_muestras)*100), vjust=-1, size=3) +
# Finalmente añadimos un título acorde.
ggtitle("Proporción Intervalos de Confianza en porcentaje \n n = 5000, t = 30") +
theme(plot.title = element_text(hjust = 0.5))
plot2
sat_gpa <- read.csv("SAT_GPA.csv")
head(sat_gpa)
summary(sta_gpa)
summary(sat_gpa)
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
library(corrplot)
corrplot(pearson_matrix, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 50)
summary(sat_gpa)
sum(is.na(hdb))
summary(sat_gpa)
sum(is.na(sat_gpa))
summary(sat_gpa)
sapply(datos, function(x) sum(is.na(x)))
summary(sat_gpa)
sapply(sat_gpa, function(x) sum(is.na(x)))
sat_gpa <- read.csv("SAT_GPA.csv")
head(sat_gpa)
summary(sat_gpa)
sapply(sat_gpa, function(x) sum(is.na(x)))
sapply(sat_gpa, function(x) sum(is.na(x)))
datos <- datos[!is.na(sar_gpa$Bangla),]
sapply(sat_gpa, function(x) sum(is.na(x)))
sat_gpa <- sat_gpa[!is.na(sar_gpa$Bangla),]
sapply(sat_gpa, function(x) sum(is.na(x)))
sat_gpa <- sat_gpa[!is.na(sat_gpa$Bangla),]
sapply(sat_gpa, function(x) sum(is.na(x)))
sat_gpa <- sat_gpa[!is.na(sat_gpa$Bangla),]
sapply(sat_gpa, function(x) sum(is.na(x)))
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
library(corrplot)
corrplot(pearson_matrix, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 50)
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
library(corrplot)
corrplot(pearson_matrix, type = "upper", tl.col = "black", tl.srt = 50)
# Plot de Intervalos de confianza (ver respuesta esperada)
# Utilizamos el dataframe creado con cada iteración
plot1 <- ggplot(confidence, aes(mean, c(1:5000), colour = group)) +
geom_point() +  # Creamos un gráfico de puntos
xlim(0, 1.5) +  # Añadimos límites para una visualización comoda
scale_color_manual(values=c("darkturquoise", "deeppink3")) +  # Colores de cada punto
# Graficamos con geom_errorbar horizontal el intervalo de confianza por cada
# iteración. Este se calcula como la media calculada más-menos el error calculado.
geom_errorbarh(aes(xmax = mean + error, xmin = mean - error)) +
# Añadimos una recta vertical que indique la media real.
geom_vline(aes(xintercept=exp.mean),
color="black", linetype="dotted", size=0.5) +
# Finalmente añadimos labels y un título.
labs(x="Means", y="Iteration") +
ggtitle("Intervalos de Confianza \n n = 5000, t = 30") +
theme(plot.title = element_text(hjust = 0.5))
plot1
View(sat_gpa)
mybootstrap <- function(x, fun, nRuns, size, alpha){
values <- vector()
for (i in 1: nRuns){
samp.i <- sample(x, size = size, replace = T)
values[i] <- fun(samp.i)
}
point.est <- fun(x)
se <- sd(values)
l.CI <- quantile(values, alpha/2)
u.CI <- quantile(values, 1-alpha/2)
return(c("Point Estimate" = point.est,
"Standart error" = se,
"Lower CI Limit" = l.CI,
"Upper CI Limit" = u.CI))
}
mybootstrap(sat_gpa$Gpa, se, 5000, 125, 0.05)
mybootstrap(sat_gpa$Gpa, sd, 5000, 125, 0.05)
mybootstrap(sat_gpa$Gpa, cor, 5000, 125, 0.05)
mybootstrap(sat_gpa, cor , 5000, 125, 0.05)
# Calculo de la matriz de correlacion para su visualización
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
# Visualización de la matriz de correlación
library(corrplot)
corrplot(pearson_matrix, type = "upper", tl.col = "black", tl.srt = 50)
# Valor de la correlación de Total y GPA:
pearson_matrix[11, 10]
# Calculo de la matriz de correlacion para su visualización
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
# Visualización de la matriz de correlación
library(corrplot)
corrplot(pearson_matrix, type = "upper", tl.col = "black", tl.srt = 50)
# Valor de la correlación de Total y GPA:
pearson_matrix[11, 10]
# Calculo de la matriz de correlacion para su visualización
pearson_matrix = cor(sat_gpa, method = "pearson")
round(pearson_matrix, 3)
# Visualización de la matriz de correlación
library(corrplot)
corrplot(pearson_matrix, type = "upper", tl.col = "black", tl.srt = 50)
# Valor de la correlación de Total y GPA:
pearson_matrix[11, 10]
mybootstrap(sat_gpa[10:11], cor , 5000, 125, 0.05)s
mybootstrap(sat_gpa[10:11], cor , 5000, 125, 0.05)
